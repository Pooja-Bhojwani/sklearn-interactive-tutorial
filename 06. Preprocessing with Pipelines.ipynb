{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Pipelines and Preprocessing steps\n",
    "Since we now know about different scikit learn functions, let's try to learn how do we tie different steps together! \n",
    "\n",
    "By the end of this tutorial you'll know:\n",
    "1. Different pre-processing steps which can be done on our data\n",
    "2. How to tie the transformers and estimators together into a pipeline\n",
    "3. How to make your own transformer\n",
    "4. Finally, how to tie it all up together!\n",
    "\n",
    "### Scikit Learn Pipelines\n",
    "As per the documentation, \n",
    "\"Sequentially apply a list of transforms and a final estimator.\n",
    "    Intermediate steps of the pipeline must be 'transforms', that is, they\n",
    "    must implement fit and transform methods.\n",
    "    The final estimator only needs to implement fit.\"\n",
    "For more information click here : (https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/pipeline.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                   int64\n",
      "Reason for absence                  object\n",
      "Month of absence                     int64\n",
      "Day of the week                     object\n",
      "Distance from Residence to Work    float64\n",
      "Service time                       float64\n",
      "Age                                float64\n",
      "Work load Average/day              float64\n",
      "Hit target                           int64\n",
      "Disciplinary failure                 int64\n",
      "Education                           object\n",
      "Number of Children                   int64\n",
      "Social drinker                       int64\n",
      "Social smoker                        int64\n",
      "Pet                                  int64\n",
      "Weight                               int64\n",
      "Height                               int64\n",
      "Body mass index                      int64\n",
      "Absenteeism time in hours            int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics for Target Variable: \n",
      " count    749.000000\n",
      "mean       8.080107\n",
      "std       17.001698\n",
      "min        0.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        8.000000\n",
      "max      120.000000\n",
      "Name: Absenteeism time in hours, dtype: float64\n",
      "(749, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Patient follow-up</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>No reason given</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>High school</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>51.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Diseases of the eye and adnexa</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>51.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Medical consultation</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>172</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>Blood donation</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>168</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>Injury, poisoning, and certain other consequen...</td>\n",
       "      <td>7</td>\n",
       "      <td>Monday</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>196</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Medical consultation</td>\n",
       "      <td>7</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>172</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 Reason for absence  Month of absence  \\\n",
       "0  11                                  Patient follow-up                 7   \n",
       "1  36                                    No reason given                 7   \n",
       "2   3                                     Blood donation                 7   \n",
       "3   7                     Diseases of the eye and adnexa                 7   \n",
       "4  11                                     Blood donation                 7   \n",
       "5   3                                     Blood donation                 7   \n",
       "6  10                               Medical consultation                 7   \n",
       "7  20                                     Blood donation                 7   \n",
       "8  14  Injury, poisoning, and certain other consequen...                 7   \n",
       "9   1                               Medical consultation                 7   \n",
       "\n",
       "  Day of the week  Distance from Residence to Work  Service time   Age  \\\n",
       "0         Tuesday                             36.0          13.0  33.0   \n",
       "1         Tuesday                             13.0          18.0  50.0   \n",
       "2       Wednesday                             51.0          18.0  38.0   \n",
       "3        Thursday                              NaN          14.0  39.0   \n",
       "4        Thursday                             36.0          13.0  33.0   \n",
       "5          Friday                             51.0          18.0  38.0   \n",
       "6          Friday                             52.0           3.0  28.0   \n",
       "7          Friday                             50.0          11.0  36.0   \n",
       "8          Monday                             12.0          14.0  34.0   \n",
       "9          Monday                             11.0          14.0  37.0   \n",
       "\n",
       "   Work load Average/day   Hit target  Disciplinary failure     Education  \\\n",
       "0                 239.554          97                     0   High school   \n",
       "1                 239.554          97                     1   High school   \n",
       "2                 239.554          97                     0   High school   \n",
       "3                 239.554          97                     0   High school   \n",
       "4                 239.554          97                     0   High school   \n",
       "5                 239.554          97                     0   High school   \n",
       "6                 239.554          97                     0   High school   \n",
       "7                 239.554          97                     0   High school   \n",
       "8                 239.554          97                     0   High school   \n",
       "9                 239.554          97                     0  Postgraduate   \n",
       "\n",
       "   Number of Children  Social drinker  Social smoker  Pet  Weight  Height  \\\n",
       "0                   2               1              0    1      90     172   \n",
       "1                   1               1              0    0      98     178   \n",
       "2                   0               1              0    0      89     170   \n",
       "3                   2               1              1    0      68     168   \n",
       "4                   2               1              0    1      90     172   \n",
       "5                   0               1              0    0      89     170   \n",
       "6                   1               1              0    4      80     172   \n",
       "7                   4               1              0    0      65     168   \n",
       "8                   2               1              0    0      95     196   \n",
       "9                   1               0              0    1      88     172   \n",
       "\n",
       "   Body mass index  Absenteeism time in hours  \n",
       "0               30                          4  \n",
       "1               31                          0  \n",
       "2               31                          2  \n",
       "3               24                          4  \n",
       "4               30                          2  \n",
       "5               31                          2  \n",
       "6               27                          8  \n",
       "7               23                          4  \n",
       "8               25                         40  \n",
       "9               29                          8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/data.csv', index_col=0)\n",
    "print(data.dtypes)\n",
    "print()\n",
    "print('Summary Statistics for Target Variable: \\n', data['Absenteeism time in hours'].describe())\n",
    "print(data.shape)\n",
    "# we have a mix of categorical, numeric, and string data.\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps\n",
    "\n",
    "Before jumping to creating a pipeline, let's start by following some preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                 0\n",
      "Reason for absence                 0\n",
      "Month of absence                   0\n",
      "Day of the week                    0\n",
      "Distance from Residence to Work    1\n",
      "Service time                       3\n",
      "Age                                6\n",
      "Work load Average/day              0\n",
      "Hit target                         0\n",
      "Disciplinary failure               0\n",
      "Education                          0\n",
      "Number of Children                 0\n",
      "Social drinker                     0\n",
      "Social smoker                      0\n",
      "Pet                                0\n",
      "Weight                             0\n",
      "Height                             0\n",
      "Body mass index                    0\n",
      "Absenteeism time in hours          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jot down the transformations which we need to do on data before training:\n",
    "1. Impute missing values\n",
    "2. Convert categorical columns to numerical values\n",
    "3. Scale/Discretizitation/Binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imputation of missing values:\n",
    "\n",
    "We will learn techniques to impute numerical values and categorical values using SimpleImputer.\n",
    "\n",
    "Documentation of SimpleImputer can be found here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "\n",
    "and Categorical Imputer can be found here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select the columns which need imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_columns = [\"Distance from Residence to Work\", \"Service time\", \"Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply imputers on columns and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "impute_df = pd.DataFrame(imp.fit_transform(data[impute_columns]),columns=impute_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from Residence to Work    0\n",
      "Service time                       0\n",
      "Age                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(impute_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert Categorical columns to numeric columns\n",
    "\n",
    "We can get ORDINAL and ONE_HOT_ENCODING from scikit learn.\n",
    "\n",
    "But the library, category_encoders (http://contrib.scikit-learn.org/categorical-encoding/index.html) offers a lot of different encoding techniques!\n",
    "\n",
    "Check out this cool article for WOE encoding:\n",
    "https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by making a list of columns which need categorical encoding. Let's try two encodings for now, one-hot and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_column = ['Reason for absence']\n",
    "one_hot_encode_column = ['Education', 'Day of the week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/s2917623/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.14.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.21.3)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.23.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
      "Requirement already satisfied: six in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/s2917623/anaconda3/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2018.4)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder(use_cat_names=True)\n",
    "one_hot_encoded_df = one_hot.fit_transform(data[one_hot_encode_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education_High school</th>\n",
       "      <th>Education_Postgraduate</th>\n",
       "      <th>Education_Graduate</th>\n",
       "      <th>Education_Master and Doctor</th>\n",
       "      <th>Day of the week_Tuesday</th>\n",
       "      <th>Day of the week_Wednesday</th>\n",
       "      <th>Day of the week_Thursday</th>\n",
       "      <th>Day of the week_Friday</th>\n",
       "      <th>Day of the week_Monday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education_High school  Education_Postgraduate  Education_Graduate  \\\n",
       "0                      1                       0                   0   \n",
       "1                      1                       0                   0   \n",
       "2                      1                       0                   0   \n",
       "3                      1                       0                   0   \n",
       "4                      1                       0                   0   \n",
       "\n",
       "   Education_Master and Doctor  Day of the week_Tuesday  \\\n",
       "0                            0                        1   \n",
       "1                            0                        1   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   Day of the week_Wednesday  Day of the week_Thursday  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          1                         0   \n",
       "3                          0                         1   \n",
       "4                          0                         1   \n",
       "\n",
       "   Day of the week_Friday  Day of the week_Monday  \n",
       "0                       0                       0  \n",
       "1                       0                       0  \n",
       "2                       0                       0  \n",
       "3                       0                       0  \n",
       "4                       0                       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoded_df = ordinal_encoder.fit_transform(data[label_encode_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason for absence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason for absence\n",
       "0                   1\n",
       "1                   2\n",
       "2                   3\n",
       "3                   4\n",
       "4                   3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Scale/Discretizitation/Binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify the columns for binning/scaling and discretizitation\n",
    "\n",
    "a. Discretization:\n",
    "    Discretization, also known as quantization or binning, divides a continuous feature into a pre-specified number of categories (bins), and thus makes the data discrete.\n",
    "    \n",
    "Sklearn provides a KBinsDiscretizer class that can take care of this. The only thing you have to specify are the number of bins (n_bins) for each feature and how to encode these bins (ordinal, onehot or onehot-dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to discretize on some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discretize_column = [\"Weight\"]\n",
    "disc = KBinsDiscretizer(n_bins=3, encode='ordinal', \n",
    "                        strategy='uniform')\n",
    "discrete_df = pd.DataFrame(disc.fit_transform(data[discretize_column]),columns=discretize_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have done the followin steps:\n",
    "\n",
    "1. Imputation........done\n",
    "2. Categorical and numerical encoding..........done\n",
    "3. Discretization.......done\n",
    "\n",
    "Time to tie it all together... But how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.loc[:,'Absenteeism time in hours']\n",
    "features = data.drop('Absenteeism time in hours', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate our own transformer to select columns from dataframe\n",
    "\n",
    "Remember TransformerMixin and BaseEstimator from previous class?\n",
    "What do they do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the column selection process simpler, let's make lists of columns which we need to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Distance from Residence to Work',\n",
    "                   'Service time',\n",
    "                   'Work load Average/day ',\n",
    "                   'Hit target',\n",
    "                   'Height',\n",
    "                   'Body mass index']\n",
    "\n",
    "discrete_columns = ['ID',\n",
    "                  'Age',\n",
    "                  'Month of absence',\n",
    "                  'Disciplinary failure',\n",
    "                  'Number of Children',\n",
    "                  'Social drinker', \n",
    "                  'Social smoker', \n",
    "                  'Pet']\n",
    "\n",
    "bin_column = ['Weight']\n",
    "\n",
    "impute_columns = [\"Distance from Residence to Work\", \"Service time\", \"Age\"]\n",
    "\n",
    "label_encode_column = ['Reason for absence']\n",
    "one_hot_encode_column = ['Education', 'Day of the week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate pipeline for each of the transformation required and stack them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline \n",
    "\n",
    "##Using Pipeline and FeatureUnion to stack different pipelines\n",
    "impute_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(impute_columns)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "bin_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(bin_column)),\n",
    "    ('Binning', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')),\n",
    "    ])\n",
    "label_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(label_encode_column)),\n",
    "    ('LabelEncoder', OrdinalEncoder()),\n",
    "    ])\n",
    "one_hot_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(one_hot_encode_column)),\n",
    "    ('LabelEncoder', OneHotEncoder()),\n",
    "    ])\n",
    "scaler_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(numeric_columns)),\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "processing_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"impute_pipeline\", impute_pipeline),\n",
    "    (\"bin_pipeline\", bin_pipeline),\n",
    "    (\"label_encode\", label_encode),\n",
    "    (\"one_hot_encode\", one_hot_encode),\n",
    "    ])\n",
    "\n",
    "# full_pipeline = FeatureUnion(transformer_list=[\n",
    "#     (\"processing\", processing_pipeline),\n",
    "#     (\"scaler_pipeline\", scaler_pipeline),\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add a final classifier to complete this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('processing_data',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('impute_pipeline',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ColumnSelector(columns=['Distance '\n",
       "                                                                                          'from '\n",
       "                                                                                          'Residence '\n",
       "                                                                                          'to '\n",
       "                                                                                          'Work',\n",
       "                                                                                          'Service '\n",
       "                                                                                          'time',\n",
       "                                                                                          'Age'])),\n",
       "                                                                 ('imputer',\n",
       "                                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                                copy=True,\n",
       "                                                                                fill_value=None,\n",
       "                                                                                missing_values=nan,\n",
       "                                                                                strategy='median',\n",
       "                                                                                verbos...\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('classifier',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=-1,\n",
       "                                       oob_score=False, random_state=1,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finalpipeline = (make_pipeline(processing_pipeline, RandomForestRegressor(random_state=1, \n",
    "#                                                                          n_jobs=-1, \n",
    "#                                                                          n_estimators=100)))\n",
    "finalpipeline = Pipeline([\n",
    "    ('processing_data', processing_pipeline),\n",
    "    ('classifier', RandomForestRegressor(random_state=1, n_jobs=-1, n_estimators=100)),\n",
    "    ])\n",
    "# Fitting the pipeline\n",
    "finalpipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.40463209  5.137       4.2577619   1.57494444  2.39816667  4.7720119\n",
      "  1.09257143  3.24675458  3.0523981   7.72833333  8.15285714  7.8805\n",
      "  5.992       5.09916667  1.26842857  3.21165873  2.55283333 23.54107143\n",
      "  1.58418615  2.67547006  2.12961039  2.87536538  2.53075649  0.99\n",
      "  5.1725      0.11625     2.00622944 41.805       5.992      11.193\n",
      "  5.9625      8.34195382  2.94333333  3.40463209  2.60630744  4.9363254\n",
      "  5.09916667  6.10266667  2.67547006 63.21833333 84.35        8.23166667\n",
      " 25.19333333  2.81603175  2.37538844  0.68       19.08166667  2.95346429\n",
      "  2.26252056 14.21233333  2.90066667 25.19333333  2.60630744  2.90066667\n",
      "  1.57494444  1.730869   26.4         7.592       6.6595      1.730869\n",
      "  7.19666667  5.2329261   7.102       7.365       0.54        5.63180952\n",
      "  2.12961039 14.16358333  5.689       4.10783333  3.33816126  8.28216667\n",
      " 55.112       2.16696609  3.79535195  9.77216667  4.3945      4.9363254\n",
      "  2.23166667  6.97033333  2.08868254  9.90533333  5.38416667  7.47866667\n",
      "  1.935       3.65880952  3.73270833  2.60630744  5.9625      2.95666667\n",
      "  1.57494444  5.29666667  7.59933333  8.52025    12.22666667 11.77788095\n",
      "  1.58418615 11.8005      5.598       2.26252056  2.39875     2.44233358\n",
      "  2.70751515  0.1         4.94052381  1.16380952  3.62533333 52.13142857\n",
      "  4.96366667 10.57066667  2.12961039  5.2329261   7.592      11.758\n",
      "  7.92        8.31238095 87.24857143 10.8695      2.41645238  0.\n",
      "  2.16696609  7.26166667  5.2329261   1.32658333  7.59333333  2.90066667\n",
      " 48.14666667  3.40463209  2.934       2.52794444 10.58183333  6.6\n",
      "  2.04        2.5505119   7.592       4.9363254   1.66771429  2.29030303\n",
      "  7.11090476  3.55838095  3.65880952  2.16696609  1.          7.04333333\n",
      "  3.776       7.776       2.6664881  11.34711111  2.59695022  6.81166667]\n",
      "121.92737238381885\n"
     ]
    }
   ],
   "source": [
    "y_pred = finalpipeline.predict(x_test)\n",
    "print(y_pred)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.: Add scaling of numeric data to check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('featureunion',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('numeric_pipeline',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ColumnSelector(columns=['Distance '\n",
       "                                                                                          'from '\n",
       "                                                                                          'Residence '\n",
       "                                                                                          'to '\n",
       "                                                                                          'Work',\n",
       "                                                                                          'Service '\n",
       "                                                                                          'time',\n",
       "                                                                                          'Work '\n",
       "                                                                                          'load '\n",
       "                                                                                          'Average/day ',\n",
       "                                                                                          'Hit '\n",
       "                                                                                          'target',\n",
       "                                                                                          'Height',\n",
       "                                                                                          'Body '\n",
       "                                                                                          'mass '\n",
       "                                                                                          'index'])),\n",
       "                                                                 ('imputer',\n",
       "                                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                                copy=Tru...\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=-1,\n",
       "                                       oob_score=False, random_state=1,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solutions/scalarSol.py\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "impute_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(impute_columns)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "bin_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(bin_column)),\n",
    "    ('Binning', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')),\n",
    "    ])\n",
    "label_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(label_encode_column)),\n",
    "    ('LabelEncoder', OrdinalEncoder()),\n",
    "    ])\n",
    "one_hot_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(one_hot_encode_column)),\n",
    "    ('LabelEncoder', OneHotEncoder()),\n",
    "    ])\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(numeric_columns)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"numeric_pipeline\", numeric_pipeline),\n",
    "    (\"bin_pipeline\", bin_pipeline),\n",
    "    (\"label_encode\", label_encode),\n",
    "    (\"one_hot_encode\", one_hot_encode),\n",
    "    ])\n",
    "\n",
    "finalpipeline = (make_pipeline(full_pipeline, RandomForestRegressor(random_state=1, \n",
    "                                                                          n_jobs=-1, \n",
    "                                                                        n_estimators=100)))\n",
    "# Fitting the pipeline\n",
    "finalpipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Add your own transformer to binarize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/binarySol.py\n",
    "class BinarizeTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold = 0):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        cond = x > self.threshold\n",
    "        not_cond = np.logical_not(cond)\n",
    "        x[cond] = 1\n",
    "        x[not_cond] = 0\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test on:\n",
    "X = np.arange(10)\n",
    "binarizer = BinarizeTransformer(threshold=5)\n",
    "binarizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Create binarized transformation for weight instead of binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('featureunion',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('numeric_pipeline',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ColumnSelector(columns=['Distance '\n",
       "                                                                                          'from '\n",
       "                                                                                          'Residence '\n",
       "                                                                                          'to '\n",
       "                                                                                          'Work',\n",
       "                                                                                          'Service '\n",
       "                                                                                          'time',\n",
       "                                                                                          'Work '\n",
       "                                                                                          'load '\n",
       "                                                                                          'Average/day ',\n",
       "                                                                                          'Hit '\n",
       "                                                                                          'target',\n",
       "                                                                                          'Height',\n",
       "                                                                                          'Body '\n",
       "                                                                                          'mass '\n",
       "                                                                                          'index'])),\n",
       "                                                                 ('imputer',\n",
       "                                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                                copy=Tru...\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=-1,\n",
       "                                       oob_score=False, random_state=1,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solutions/binaryTransform.py\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "impute_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(impute_columns)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "bin_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(bin_column)),\n",
    "    ('Binning', BinarizeTransformer(threshold=5)),\n",
    "    ])\n",
    "label_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(label_encode_column)),\n",
    "    ('LabelEncoder', OrdinalEncoder()),\n",
    "    ])\n",
    "one_hot_encode = Pipeline([\n",
    "    ('selector', ColumnSelector(one_hot_encode_column)),\n",
    "    ('LabelEncoder', OneHotEncoder()),\n",
    "    ])\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(numeric_columns)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"numeric_pipeline\", numeric_pipeline),\n",
    "    (\"bin_pipeline\", bin_pipeline),\n",
    "    (\"label_encode\", label_encode),\n",
    "    (\"one_hot_encode\", one_hot_encode),\n",
    "    ])\n",
    "\n",
    "finalpipeline = (make_pipeline(full_pipeline, RandomForestRegressor(random_state=1, \n",
    "                                                                          n_jobs=-1, \n",
    "                                                                        n_estimators=100)))\n",
    "# Fitting the pipeline\n",
    "finalpipeline.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Perform grid search on this final pipeline\n",
    "\n",
    "Hint: Refer to assignment 2 alternative solution\n",
    "* Use randomforestregressor\n",
    "* and couple of values to do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestregressor__n_estimators': [100, 500, 750, 1000], 'randomforestregressor__max_features': [3, 4, 5], 'randomforestregressor__max_depth': [5, 40, 75, 110, None]}\n",
      "Grid search\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   50.8s finished\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "/Users/s2917623/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# %load solutions/gridSearch.py\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100, 500, 750, 1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = [3, 4, 5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "              }\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "print(\"Grid search\")\n",
    "print('\\n')\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "clf = GridSearchCV(finalpipeline, random_grid, n_jobs=-1, verbose=True, scoring=scoring)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf_preds = clf.predict(x_test)\n",
    "clf_preds = pd.Series(clf_preds)\n",
    "clf_preds = clf_preds.rename(\"Grid Search Predicted values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__max_depth': 40,\n",
       " 'randomforestregressor__max_features': 3,\n",
       " 'randomforestregressor__n_estimators': 500}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.7311019747920415"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
